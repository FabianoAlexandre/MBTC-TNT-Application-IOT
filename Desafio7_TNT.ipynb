{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Desafio7-TNT.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FabianoAlexandre/MBTC-TNT-Application-IOT/blob/master/Desafio7_TNT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "roB4fbh7FH89",
        "colab_type": "text"
      },
      "source": [
        "# MARATONA BEHIND THE CODE 2020\n",
        "\n",
        "## DESAFIO 7 - TNT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai3q4XnOFH8-",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRvbf4FgFH8_",
        "colab_type": "text"
      },
      "source": [
        "## Installing Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjGGjKxwFH9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "3475e934-98b3-4746-a335-79b330d4fe1b"
      },
      "source": [
        "!pip install scikit-learn --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.23.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UurE8sQaFH9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "b385ece8-f7e0-4ba6-c7c5-b2f5e0410d9b"
      },
      "source": [
        "!pip install xgboost --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xgboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/5c/1133b5b8f4f2fa740ff27abdd35b8e79ce6e1f8d6480a07e9bce1cdafea2/xgboost-1.2.0-py3-none-manylinux2010_x86_64.whl (148.9MB)\n",
            "\u001b[K     |████████████████████████████████| 148.9MB 62kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Installing collected packages: xgboost\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aHe9kAMFH9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ab9ae3e7-4088-4f1d-a50f-51498b0ecb4e"
      },
      "source": [
        "!pip install imblearn --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imblearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied, skipping upgrade: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (from imblearn) (0.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (0.23.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ1rFMJqFn-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "4821c4ca-febc-4329-e21b-bad63bb5b95c"
      },
      "source": [
        "!pip install Cloudant"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Cloudant\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/c0/e648f7ba7cb1f1295bc9c7271c7df00d4eb82cde86e8d395c4a69e1b0674/cloudant-2.14.0.tar.gz (61kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from Cloudant) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.7.0->Cloudant) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.7.0->Cloudant) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.7.0->Cloudant) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.7.0->Cloudant) (3.0.4)\n",
            "Building wheels for collected packages: Cloudant\n",
            "  Building wheel for Cloudant (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Cloudant: filename=cloudant-2.14.0-cp36-none-any.whl size=75193 sha256=9af50cf7b46f57291b212c942ae2e2a3f7f56c93688dcce466b8bae15ac0f331\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/88/1a/4211b73f602be4834dc4639f947fba1c8266326b60fd22103b\n",
            "Successfully built Cloudant\n",
            "Installing collected packages: Cloudant\n",
            "Successfully installed Cloudant-2.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8laa3dTyFsQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cloudant import Cloudant\n",
        "u = 'fa8daf0c-2837-4d21-b071-abe0bd98ce7f-bluemix'\n",
        "p = 'e0a6a7699e780942a75414dd8dd8c8fc250791449b2f4b1b9aca1e21a5c48c4f'\n",
        "a = 'fa8daf0c-2837-4d21-b071-abe0bd98ce7f-bluemix'\n",
        "client = Cloudant(u, p, account=a, connect=True, auto_renew=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xs2kwQfGQvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db = client['fabiano-iot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miTbXFsjGXxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71fe9f3f-c442-4482-86d2-7911bf2df666"
      },
      "source": [
        "response = db.all_docs(limit=1000, include_docs=True)\n",
        "\n",
        "docs = []\n",
        "for r in response['rows']:\n",
        "  docs.append(r['doc'])\n",
        "type(docs)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keQysy3PgnGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "with open(\"C:\\Users\\fabia\\OneDrive\\Documentos\", 'w', newline='') as saida:\n",
        "  escrever = csv.writer(saida)\n",
        "  for i in range(1, 100):\n",
        "    print(i)\n",
        "    escrever.writerow([1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_HhkV6_FH9P",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL66dAjSFH9Q",
        "colab_type": "text"
      },
      "source": [
        "## Download dos conjuntos de dados em formato .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wa-Df-jHBXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "76a19bfe-9747-4022-afa4-648ce196f3e3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_training_dataset.tail()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>_rev</th>\n",
              "      <th>Tempo</th>\n",
              "      <th>Estação</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LONG</th>\n",
              "      <th>Movimentação</th>\n",
              "      <th>Original_473</th>\n",
              "      <th>Original_269</th>\n",
              "      <th>Zero</th>\n",
              "      <th>Maçã-Verde</th>\n",
              "      <th>Tangerina</th>\n",
              "      <th>Citrus</th>\n",
              "      <th>Açaí-Guaraná</th>\n",
              "      <th>Pêssego</th>\n",
              "      <th>TARGET</th>\n",
              "      <th>row</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>05d781bf081bc16008b3a3dd4066ac79</td>\n",
              "      <td>1-e424a6c8a0c8eb484b7e0ed77f2565b1</td>\n",
              "      <td>2018-6-14</td>\n",
              "      <td>Butantã</td>\n",
              "      <td>-23.5844</td>\n",
              "      <td>-46.7252</td>\n",
              "      <td>67785</td>\n",
              "      <td>57</td>\n",
              "      <td>45</td>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>24</td>\n",
              "      <td>27</td>\n",
              "      <td>25</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>9524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>05d781bf081bc16008b3a3dd406b2b43</td>\n",
              "      <td>1-6207b046d4a15020886797759d15db2c</td>\n",
              "      <td>2019-4-20</td>\n",
              "      <td>Paraíso</td>\n",
              "      <td>-23.57677</td>\n",
              "      <td>-46.63933</td>\n",
              "      <td>73442</td>\n",
              "      <td>73</td>\n",
              "      <td>61</td>\n",
              "      <td>53</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>REABASTECER</td>\n",
              "      <td>470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>05d781bf081bc16008b3a3dd406b9279</td>\n",
              "      <td>1-89c04856a6ca4f6252ef7f419cb0e4f7</td>\n",
              "      <td>2018-9-20</td>\n",
              "      <td>Butantã</td>\n",
              "      <td>-23.5844</td>\n",
              "      <td>-46.7252</td>\n",
              "      <td>66423</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>52</td>\n",
              "      <td>12</td>\n",
              "      <td>43</td>\n",
              "      <td>23</td>\n",
              "      <td>38</td>\n",
              "      <td>33</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>9620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>05d781bf081bc16008b3a3dd406e74f7</td>\n",
              "      <td>1-494fb7b056a57bf8f49acf45a8992f59</td>\n",
              "      <td>2019-7-7</td>\n",
              "      <td>Paraíso</td>\n",
              "      <td>-23.57677</td>\n",
              "      <td>-46.63933</td>\n",
              "      <td>70586</td>\n",
              "      <td>86</td>\n",
              "      <td>28</td>\n",
              "      <td>36</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>22</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>05d781bf081bc16008b3a3dd406e8a45</td>\n",
              "      <td>1-79ad760c14d73bafd240cb7789783918</td>\n",
              "      <td>2019-11-13</td>\n",
              "      <td>Faria Lima</td>\n",
              "      <td>-23.5675</td>\n",
              "      <td>-46.6929</td>\n",
              "      <td>53942</td>\n",
              "      <td>38</td>\n",
              "      <td>55</td>\n",
              "      <td>27</td>\n",
              "      <td>42</td>\n",
              "      <td>13</td>\n",
              "      <td>37</td>\n",
              "      <td>33</td>\n",
              "      <td>17</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>8593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  _id  ...   row\n",
              "495  05d781bf081bc16008b3a3dd4066ac79  ...  9524\n",
              "496  05d781bf081bc16008b3a3dd406b2b43  ...   470\n",
              "497  05d781bf081bc16008b3a3dd406b9279  ...  9620\n",
              "498  05d781bf081bc16008b3a3dd406e74f7  ...   547\n",
              "499  05d781bf081bc16008b3a3dd406e8a45  ...  8593\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xwcX7riQzQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c069d07d-d63b-46cf-8612-b3ec3bc1248d"
      },
      "source": [
        "df_training_dataset.isna().sum()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_id             0\n",
              "_rev            0\n",
              "Tempo           0\n",
              "Estação         0\n",
              "LAT             0\n",
              "LONG            0\n",
              "Movimentação    0\n",
              "Original_473    0\n",
              "Original_269    0\n",
              "Zero            0\n",
              "Maçã-Verde      0\n",
              "Tangerina       0\n",
              "Citrus          0\n",
              "Açaí-Guaraná    0\n",
              "Pêssego         0\n",
              "TARGET          0\n",
              "row             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkQ3c_8qJNJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "b4b86340-2bf8-445e-9523-e1e9f015afdd"
      },
      "source": [
        "df_training_dataset.info()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 17 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   _id           500 non-null    object\n",
            " 1   _rev          500 non-null    object\n",
            " 2   Tempo         500 non-null    object\n",
            " 3   Estação       500 non-null    object\n",
            " 4   LAT           500 non-null    object\n",
            " 5   LONG          500 non-null    object\n",
            " 6   Movimentação  500 non-null    object\n",
            " 7   Original_473  500 non-null    object\n",
            " 8   Original_269  500 non-null    object\n",
            " 9   Zero          500 non-null    object\n",
            " 10  Maçã-Verde    500 non-null    object\n",
            " 11  Tangerina     500 non-null    object\n",
            " 12  Citrus        500 non-null    object\n",
            " 13  Açaí-Guaraná  500 non-null    object\n",
            " 14  Pêssego       500 non-null    object\n",
            " 15  TARGET        500 non-null    object\n",
            " 16  row           500 non-null    int64 \n",
            "dtypes: int64(1), object(16)\n",
            "memory usage: 66.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycvh1sEoVyiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset['Açaí-Guaraná'] = df_training_dataset['Açaí-Guaraná'].astype(int64)\n",
        "df_training_dataset['Estação'] = df_training_dataset['Estação'].astype(int64)\n",
        "df_training_dataset['Citrus'] = df_training_dataset['Citrus'].astype(int64)\n",
        "df_training_dataset['Maçã-Verde'] = df_training_dataset['Maçã-Verde'].astype(int64)\n",
        "df_training_dataset['Pêssego'] = df_training_dataset['Pêssego'].astype(int64)\n",
        "df_training_dataset['Tangerina'] = df_training_dataset['Tangerina'].astype(int64)\n",
        "df_training_dataset['LAT'] = df_training_dataset['LAT'].astype(float)\n",
        "df_training_dataset['LONG'] = df_training_dataset['LONG'].astype(float)\n",
        "df_training_dataset['Movimentação'] = df_training_dataset['Movimentação'].astype(int64)\n",
        "df_training_dataset['Original_473'] = df_training_dataset['Original_473'].astype(int64)\n",
        "df_training_dataset['Original_269'] = df_training_dataset['Original_269'].astype(int64)\n",
        "df_training_dataset['Zero'] = df_training_dataset['Zero'].astype(int64)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMXzAItkLRVF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "89efbdbe-3d3e-4fff-80bb-0431fa43c97b"
      },
      "source": [
        "df_training_dataset.nunique()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_id             500\n",
              "_rev            494\n",
              "Tempo           370\n",
              "Estação          25\n",
              "LAT              25\n",
              "LONG             25\n",
              "Movimentação    493\n",
              "Original_473     79\n",
              "Original_269     64\n",
              "Zero             62\n",
              "Maçã-Verde       43\n",
              "Tangerina        42\n",
              "Citrus           43\n",
              "Açaí-Guaraná     41\n",
              "Pêssego          42\n",
              "TARGET            2\n",
              "row             494\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebZK1x0ONQGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset['TargetNumber'] = df_training_dataset['TARGET'].map({\"NORMAL\" : 1, \"REABASTECER\" : 2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myggfJ-xa3Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvFStF6RFH9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Insira aqui o pandasDataFrame."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CnOSFMuFH9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "07ea2e2b-57be-4b8f-bb6c-15a7fbe4189f"
      },
      "source": [
        "df_training_dataset = df_data_1\n",
        "df_training_dataset.tail()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a50cc3cd1b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_training_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_training_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_data_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrJowjZeFH9k",
        "colab_type": "text"
      },
      "source": [
        "Sobre o arquivo \"training_dataset.csv\", temos algumas informações gerais sobre os pontos de vendas da TNT:\n",
        "\n",
        "**Tempo**\n",
        "\n",
        "**Estação**\n",
        "\n",
        "**LAT**\n",
        "\n",
        "**LONG**\n",
        "\n",
        "**Movimentação**\n",
        "\n",
        "**Original_473**\n",
        "\n",
        "**Original_269**\n",
        "\n",
        "**Zero**\n",
        "\n",
        "**Maçã-Verde**\n",
        "\n",
        "**Tangerina**\n",
        "\n",
        "**Citrus**\n",
        "\n",
        "**Açaí-Guaraná**\n",
        "\n",
        "**Pêssego**\n",
        "\n",
        "**TARGET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX2AgL7yFH9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lTKRU3IFH9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31QgYlKyFH9u",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## Detalhamento do desafio: classificação binária\n",
        "\n",
        "Este é um desafio cujo objetivo de negócio é a segmentação dos usuários de aplicativo de um banco. Para tal, podemos utilizar duas abordagens: aprendizado de máquina supervisionado (classificação) ou não-supervisionado (clustering). Neste desafio será aplicada a classificação, pois é disponível um dataset já com \"labels\", ou em outras palavras, já com exemplos de dados juntamente com a variável alvo.\n",
        "\n",
        "Na biblioteca scikit-learn temos diversos algoritmos para classificação. O participante é livre para utilizar o framework que desejar para completar esse desafio.\n",
        "\n",
        "Neste notebook será mostrado um exeplo de uso do algoritmo \"Decision Tree\" para classificar parte dos estudantes em seis diferentes perfís."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnsIf2H5FH9v",
        "colab_type": "text"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "A coluna-alvo neste desafio é a coluna ``TARGET``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs-pmaMeFH9w",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZrprYkKFH9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUcB11HbFH91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmAidEBOFH96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEHzLUl4FH-B",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processando o dataset antes do treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjM1-mJqFH-C",
        "colab_type": "text"
      },
      "source": [
        "### Processando valores NaN com o SimpleImputer do sklearn\n",
        "\n",
        "Para os valores NaN, usaremos a substituição pela constante 0 como **exemplo**.\n",
        "\n",
        "Você pode escolher a estratégia que achar melhor para tratar os valores nulos :)\n",
        "\n",
        "Docs: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html?highlight=simpleimputer#sklearn.impute.SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxBWbQjvFH-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "impute_zeros = SimpleImputer(\n",
        "    missing_values=np.nan,\n",
        "    strategy='constant',\n",
        "    fill_value=0,\n",
        "    verbose=0,\n",
        "    copy=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R2i8WZGFH-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
        "print(\"Valores nulos no df_training_dataset antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))\n",
        "\n",
        "# Aplicando a transformação ``SimpleImputer`` no conjunto de dados base\n",
        "impute_zeros.fit(X=df_training_dataset)\n",
        "\n",
        "# Reconstruindo um Pandas DataFrame com os resultados\n",
        "df_training_dataset_imputed = pd.DataFrame.from_records(\n",
        "    data=impute_zeros.transform(\n",
        "        X=df_training_dataset\n",
        "    ),\n",
        "    columns=df_training_dataset.columns\n",
        ")\n",
        "\n",
        "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
        "print(\"Valores nulos no df_training_dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_imputed.isnull().sum(axis = 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AwyGq9HFH-S",
        "colab_type": "text"
      },
      "source": [
        "### Eliminando colunas indesejadas\n",
        "\n",
        "Vamos **demonstrar** abaixo como usar o método **DataFrame.drop()**.\n",
        "\n",
        "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtG1o7G3FH-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset_imputed.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXxq5kYLFH-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset_rmcolumns = df_training_dataset_imputed.drop(columns=['Tempo', 'Estação', 'LAT', 'LONG', 'Movimentação'], inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgz_iYMNFH-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset_rmcolumns.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QE6ZPcAFH-j",
        "colab_type": "text"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "As colunas removidas acima são apenas para fim de exemplo, você pode usar as colunas que quiser e inclusive criar novas colunas com dados que achar importantes!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5IcJUVwFH-k",
        "colab_type": "text"
      },
      "source": [
        "### Tratamento de de variáveis categóricas\n",
        "\n",
        "Como mencionado antes, os computadores não são bons com variáveis \"categóricas\" (ou strings).\n",
        "\n",
        "Dado uma coluna com variável categórica, o que podemos realizar é a codificação dessa coluna em múltiplas colunas contendo variáveis binárias. Esse processo é chamado de \"one-hot-encoding\" ou \"dummy encoding\". Se você não é familiarizado com esses termos, você pode pesquisar mais sobre isso na internet :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SfX2SGjFH-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tratando variáveis categóricas com o método Pandas ``get_dummies()''\n",
        "# df_training = pd.get_dummies(df_training_dataset_rmcolumns, columns=['Variável a ser aplicado método getDumies()'])\n",
        "df_training = df_training_dataset_rmcolumns\n",
        "df_training.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g1cHL8XFH-p",
        "colab_type": "text"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "A coluna **TARGET** deve ser mantida como uma string. Você não precisa processar/codificar a variável-alvo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPZwCV3KFH-q",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAc6vcGtFH-r",
        "colab_type": "text"
      },
      "source": [
        "## Treinando um classificador com base em uma árvore de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfX9I_8UFH-r",
        "colab_type": "text"
      },
      "source": [
        "### Selecionando FEATURES e definindo a variável TARGET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNqa4KEuFH-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvLbzGWHFH-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = df_training[\n",
        "    [\n",
        "        'Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina',\n",
        "       'Citrus', 'Açaí-Guaraná', 'Pêssego'\n",
        "    ]\n",
        "]\n",
        "target = df_training['TARGET']  ## NÃO TROQUE O NOME DA VARIÁVEL TARGET."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2YTTSBOFH-2",
        "colab_type": "text"
      },
      "source": [
        "### Dividindo nosso conjunto de dados em conjuntos de treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deUCEI5lFH-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=133)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPJWFutyFH_A",
        "colab_type": "text"
      },
      "source": [
        "### Treinando uma árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCtyFYHnFH_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Método para criar um árvore de decisão\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "dtc = DecisionTreeClassifier(max_depth=15).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBbPPVGOFH_G",
        "colab_type": "text"
      },
      "source": [
        "### Fazendo previsões na amostra de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-a5zTywFH_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = dtc.predict(X_test)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk4GEq9QFH_N",
        "colab_type": "text"
      },
      "source": [
        "### Analisando a qualidade do modelo através da matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k90NbtobFH_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRCCyiICFH_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['NORMAL', 'REABASTECER'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WWIwapqFH_W",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6_zZmtiFH_X",
        "colab_type": "text"
      },
      "source": [
        "## Scoring dos dados necessários para entregar a solução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0U4qHQcFH_X",
        "colab_type": "text"
      },
      "source": [
        "Como entrega da sua solução, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-RospCcFH_Y",
        "colab_type": "text"
      },
      "source": [
        "### Download da \"folha de respostas\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ihzyYPEDFH_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate --content-disposition https://gitlab.com/JoaoPedroPP/datasets/-/raw/master/ntn/to_be_scored.csv\n",
        "df_to_be_scored = pd.read_csv(r'to_be_scored.csv')\n",
        "df_to_be_scored.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mjKWh3OFH_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_to_be_scored = pd.read_csv('to_be_scored.csv')\n",
        "df_to_be_scored.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYhR4jczFH_j",
        "colab_type": "text"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "O dataframe ``to_be_scored`` é a sua \"folha de respostas\". Note que a coluna \"TARGET\" não existe nessa amostra, que não pode ser então utilizada para treino de modelos de aprendizado supervisionado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "w5X7FOuvFH_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_to_be_scored.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXAMLki_FH_p",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# Atenção!\n",
        "\n",
        "# Para poder aplicar seu modelo e classificar a folha de respostas, você precisa primeiro aplicar as mesmas transformações com colunas que você aplicou no dataset de treino.\n",
        "\n",
        "# Não remova ou adicione linhas na folha de respostas. \n",
        "\n",
        "# Não altere a ordem das linhas na folha de respostas.\n",
        "\n",
        "# Ao final, as 1000 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTn0AM8EFH_q",
        "colab_type": "text"
      },
      "source": [
        "Na célula abaixo, repetimos rapidamente os mesmos passos de pré-processamento usados no exemplo dado com árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyYo5t4qFH_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1 - Removendo linhas com valores NaN\n",
        "df_to_be_scored_1 = df_to_be_scored.dropna(axis='index', how='any', subset=['Tempo', 'Estação', 'LAT', 'LONG', 'Movimentação', 'Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina', 'Citrus', 'Açaí-Guaraná', 'Pêssego'])\n",
        "\n",
        "# 2 - Inputando zeros nos valores faltantes\n",
        "impute_zeros.fit(X=df_to_be_scored_1)\n",
        "df_to_be_scored_2 = pd.DataFrame.from_records(\n",
        "    data=impute_zeros.transform(\n",
        "        X=df_to_be_scored_1\n",
        "    ),\n",
        "    columns=df_to_be_scored_1.columns\n",
        ")\n",
        "\n",
        "# 3 - Remoção de colunas\n",
        "df_to_be_scored_3 = df_to_be_scored_2.drop(columns=['Tempo', 'Estação', 'LAT', 'LONG', 'Movimentação'], inplace=False)\n",
        "\n",
        "# 4 - Encoding com \"dummy variables\" (se necessário)\n",
        "# df_to_be_scored_4 = pd.get_dummies(df_to_be_scored_3, columns=['Váriavel com dummy'])\n",
        "df_to_be_scored_4 = df_to_be_scored_3\n",
        "\n",
        "df_to_be_scored_4.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLqqc8vvFH_w",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "Pode ser verificado abaixo que as colunas da folha de resposta agora são idênticas às que foram usadas para treinar o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0h1BG0XFH_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training[\n",
        "    [\n",
        "        'Original_473', 'Original_269', 'Zero', 'Maçã-Verde', 'Tangerina',\n",
        "       'Citrus', 'Açaí-Guaraná', 'Pêssego'\n",
        "    ]\n",
        "].columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJZeMQbKFH_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_to_be_scored_4.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQHVEMacFH_5",
        "colab_type": "text"
      },
      "source": [
        "# Atenção\n",
        "\n",
        "Para todas colunas que não existirem no \"df_to_be_scored\", você pode usar a técnica abaixo para adicioná-las:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "3VjnW1cQFH_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = dtc.predict(df_to_be_scored_4)\n",
        "df_to_be_scored_4['TARGET'] = y_pred\n",
        "df_to_be_scored_4.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cT9H24lFH__",
        "colab_type": "text"
      },
      "source": [
        "### Salvando a folha de respostas como um arquivo .csv para ser submetido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErEGec7_FH__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project.save_data(file_name=\"results.csv\", data=df_to_be_scored_4.to_csv(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnHp2aC1FIAH",
        "colab_type": "text"
      },
      "source": [
        "# Atenção\n",
        "\n",
        "# A execução da célula acima irá criar um novo \"data asset\" no seu projeto no Watson Studio. Você precisará realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submissão. (os arquivos devem estar nomeados desta forma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPQ0FOn3FIAI",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## Parabéns!\n",
        "\n",
        "Se você já está satisfeito com a sua solução, vá até a página abaixo e envie os arquivos necessários para submissão.\n",
        "\n",
        "# https://tnt.maratona.dev\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa_TH1MmFIAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}